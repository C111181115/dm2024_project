{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining W6\n",
    "Name 宋柏頡\n",
    "ID C111181115\n",
    "Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "rice_cammeo_and_osmancik = fetch_ucirepo(id=545) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rice_cammeo_and_osmancik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = rice_cammeo_and_osmancik.data.features \n",
    "y = rice_cammeo_and_osmancik.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(rice_cammeo_and_osmancik.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(rice_cammeo_and_osmancik.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_df= pd.concat([X, y], axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或者使用 pandas 的 factorize 函數\n",
    "merged_df['Class'] = pd.factorize(merged_df['Class'])[0]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Plot the distribution for each x variable\n",
    "for i, column in enumerate(X.columns):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.distplot(X[column], hist=False, label=column, ax=axes[row, col])\n",
    "\n",
    "    # Set plot labels and title\n",
    "    axes[row, col].set_xlabel(\"Value\")\n",
    "    axes[row, col].set_ylabel(\"Density\")\n",
    "    axes[row, col].set_title(f\"Distribution of {column}\")\n",
    "\n",
    "    # Show the legend\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr_matrix = merged_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 设置k-fold=10\n",
    "k = 10\n",
    "\n",
    "# 初始化KFold对象\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Initialize support vector classifier model\n",
    "svc_model = SVC()\n",
    "\n",
    "# 初始化随机森林分类器模型\n",
    "rfr = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "# Add the new models to the cross_validate function\n",
    "cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring)\n",
    "cv_results_logreg = cross_validate(logreg_model, X, y, cv=kf, scoring=scoring)\n",
    "cv_results_svc = cross_validate(svc_model, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "# Print the results for each model\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", cv_results['test_accuracy'].mean())\n",
    "print(\"Precision:\", cv_results['test_precision_macro'].mean())\n",
    "print(\"Recall:\", cv_results['test_recall_macro'].mean())\n",
    "print(\"F1-score:\", cv_results['test_f1_macro'].mean())\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(\"Accuracy:\", cv_results_logreg['test_accuracy'].mean())\n",
    "print(\"Precision:\", cv_results_logreg['test_precision_macro'].mean())\n",
    "print(\"Recall:\", cv_results_logreg['test_recall_macro'].mean())\n",
    "print(\"F1-score:\", cv_results_logreg['test_f1_macro'].mean())\n",
    "\n",
    "print(\"\\nSupport Vector Classifier:\")\n",
    "print(\"Accuracy:\", cv_results_svc['test_accuracy'].mean())\n",
    "print(\"Precision:\", cv_results_svc['test_precision_macro'].mean())\n",
    "print(\"Recall:\", cv_results_svc['test_recall_macro'].mean())\n",
    "print(\"F1-score:\", cv_results_svc['test_f1_macro'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
